%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  File 31_ideal_exp.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{概要}

本章では、SCALEを使った理想実験の実行方法を説明する。
第\ref{sec:install}章で実行したSCALEのコンパイルが
正常に完了しているかどうかのチェックも含めてぜひ実施してもらいたい。


\subsection{チュートリアル実行のための推奨環境}
\label{sec:assumed_env}

本書のチュートリアルの説明は、下記の環境を前提として記述している。
コンパイラ、ライブラリについては、適宜、使用環境に合わせて読み替えること。

\begin{itemize}
 \item {\bf CPU} : 物理コアが2コア以上 %[Intel Core i5 2410M 2.3GHz 2コア/4スレッド] %、第\ref{sec:tuto_real}章は4コアを搭載
 \item {\bf Memory} : 512MB以上 %[DDR3-1333 4GB]  　　　%、第\ref{sec:tuto_real}章は2GB
 \item {\bf OS} : Linux OS x86-64  %[CentOS 6.6、CentOS 7.1、openSUSE 13.2のいずれか]
 \item {\bf コンパイラ} : GNU コンパイラ（gcc/gfortran）
 \item {\bf MPIライブラリ} : openMPI（リポジトリ経由でのインストール）
\end{itemize}

本章では、SCALEのコンパイルが正常に終了し、
すでに下記のファイルが生成されているものとして説明を行う。
\begin{verbatim} 
  scale/scale-rm/test/tutorial/bin/scale-rm
  scale/scale-rm/test/tutorial/bin/scale-rm_init
  scale/scale-rm/util/netcdf2grads_h/net2g
\end{verbatim}
これらに加えて、本章のチュートリアルでは、
描画ツールとしてgpviewとGrADSを使用する。
gpview(Gphys)とGrADSの詳細やインストール方法については、
付録 \ref{sec:env_vis_tools}節を参照のこと。


\subsection{実験設定}
%====================================================================================

実験設定として、「スコールライン」の理想実験を例にあげる。
この実験では、積乱雲が発生するときの
典型的な大気の鉛直プロファイルと対流圏下層に初期擾乱を与え、
積乱雲が発達する様子を準2次元モデルで実験する内容となっている。
実験設定は表\ref{tab:setting_ideal}に示す通りである。

\begin{table}[htb]
\begin{center}
\caption{チュートリアル理想実験の実験設定}
\begin{tabularx}{150mm}{|l|X|X|} \hline
 \rowcolor[gray]{0.9} 項目 & 設定内容 & 備考 \\ \hline
 水平格子間隔 & 東西：500 m、南北：1000 m & 東西-鉛直の面を切り取った準2次元実験である \\ \hline
 水平格子点数 & 東西：40、南北：2\footnotemark &  \\ \hline
 鉛直層数     & 97層（トップ：20 km）& 下層ほど細かい層間隔をとったストレッチ設定である \\ \hline
 側面境界条件 & 周期境界 & 東西、南北とも \\ \hline
 積分時間間隔 & 5 sec      & 雲微物理スキームは10 sec毎 \\ \hline
 積分期間     & 3,600 sec  & 720 steps \\ \hline
 データ出力間隔 & 300 sec  &  \\ \hline
 物理スキーム & 雲微物理モデルのみ使用 &
 6-class single moment bulk model \citep{tomita_2008} \\ \hline
 初期鉛直プロファイル & GCSS Case1 squall-line \citep{Redelsperger2000}&
 風のプロファイルは、\citet{Ooyama_2001}に基づいた鉛直シアを与える \\ \hline
 初期擾乱 & ウォームバブル & 水平半径4 km、
 鉛直半径3 kmの大きさを持つ最大プラス3Kの強度のウォームバブルを置く\\ \hline
\end{tabularx}
\label{tab:setting_ideal}
\end{center}
\end{table}
\footnotetext{現在は２次元実験を行うための枠組みは用意されていないが、y方向に同じ値をもつ初期値を与える事で２次元実験に相当する実験を行うことが可能である。この場合、ハロの格子数と同じ数の格子数をy方向に設定する必要がある。ハロの必要格子数については\ref{sec:dyn}参照。}



\section{実行方法}
%====================================================================================

実行の流れとしては、前準備、初期値の作成、モデル本体の実行、
後処理、そして描画といった順番で作業を進める。

\subsection{前準備}
%------------------------------------------------------
チュートリアル理想実験は、\verb|scale-rm/test/tutorial/ideal|の
ディレクトリにて実行する。
\begin{verbatim}
  $ cd scale-rm/test/tutorial/ideal
\end{verbatim}
次に、このディレクトリに、
SCALEの実行バイナリの静的リンクを張る。
\begin{verbatim}
  $ ln -s ../bin/scale-rm       ./
  $ ln -s ../bin/scale-rm_init  ./
\end{verbatim}
``\verb|scale-rm|''はモデル本体、
``\verb|scale-rm_init|''は初期値・境界値作成ツールである。
%もし、ここで説明するディレクトリとは異なる場所で実行している場合は、
%リンクを張る時のディレクトリ指定に注意すること。


\subsection{初期値作成}
%------------------------------------------------------
初期値の作成は、``\verb|scale-rm_init|''に
設定ファイル (configファイル)を与えて実行する。
``\verb|init_R20kmDX500m.conf|''には、
表\ref{tab:setting_ideal}に対応した実験設定が書き込まれている。
このconfigファイルを\verb|scale-rm_init|に与えることで、
設定ファイルの指示に従って大気の成層構造を計算し、
初期擾乱が設定される。


SCALEの基本的な実行コマンドは下記のとおりである。
\begin{verbatim}
  $ mpirun  -n  [プロセス数]  [実行バイナリ名]  [configファイル]
\end{verbatim}
[プロセス数]の部分にはMPI並列で使用したいプロセス数を記述する。
[実行バイナリ]には、\verb|scale-rm|や\verb|scale-rm_init|が入る。
そして、実験設定を記述したconfigファイルを
[configファイル]の部分に指定する。
%
例えば、
configファイルに\verb|init_R20kmDX500m.conf|を用いて、
2-MPI並列(2つのMPIプロセス)
で\verb|scale-rm_init|を実行する場合、
コマンドは次のようになる。
\begin{verbatim}
  $ mpirun  -n  2  ./scale-rm_init  init_R20kmDX500m.conf
\end{verbatim}
%
\noindent 実行が成功した場合には、コマンドラインのメッセージは
下記のように表示される。\\

\noindent {\small {\gt
\fbox{
\begin{tabularx}{140mm}{l}
 *** Start Launch System for SCALE-RM\\
 TOTAL BULK JOB NUMBER   =    1\\
 PROCESS NUM of EACH JOB =     2\\
 TOTAL DOMAIN NUMBER     =    1\\
 Flag of ABORT ALL JOBS  =  F\\
 *** a single comunicator\\
 *** a single comunicator\\
\end{tabularx}
}}}\\

\noindent この実行によって、\\
\begin{verbatim}
  init\_LOG.pe000000
  init\_00000000000.000.pe000000.nc
  init\_00000000000.000.pe000001.nc
\end{verbatim}
の3つのファイルが、現在のディレクトリ下に作成される。
``init\_LOG.pe000000''には、
コマンドラインには表示されない詳しい実行ログが記録されている。
実行が正常に終了している場合、このLOGファイルの最後に\\

\noindent {\small {\gt
\ovalbox{
\begin{tabularx}{140mm}{l}
 ++++++ Stop MPI\\
 *** Broadcast STOP signal\\
 *** MPI is peacefully finalized\\
\end{tabularx}
}}}\\

\noindent と記述される。

``init\_00000000000.000.pe000000.nc''と``init\_00000000000.000.pe000001.nc''の
2つのファイルは初期値ファイルである。
計算領域全体を2つのMPIプロセスで分割し担当するため、
2つのファイルが生成される。
もし、4-MPI並列で実行すれば、4つの初期値ファイルが生成される。
これらのファイル名の末尾が``.nc''で終わるファイルは
NetCDF形式のファイルであり、
Gphys/Ruby-DCLやncviewといったツールで直接読むことができる。


\subsection{モデル本体の実行}
%------------------------------------------------------
並列数は、初期値作成のときと同じ数を指定する。
configファイルには``\verb|run_R20kmDX500m.conf|''を指定する。
\begin{verbatim}
  $ mpirun  -n  2  ./scale-rm  run_R20kmDX500m.conf
\end{verbatim}

本書の必要要件にあった計算機であれば、2分程度で計算が終わる。
\noindent この実行によって、\\
\begin{verbatim}
  LOG.pe000000
  history.pe000000.nc
  history.pe000001.nc
  monitor.pe000000
\end{verbatim}
の4つのファイルが、現在のディレクトリ下に作成されているはずである。
``LOG.pe000000''には、
コマンドラインには表示されない詳しい実行ログが記録されている。
実行が正常に終了している場合、このLOGファイルの最後に\\

\noindent {\small {\gt
\ovalbox{
\begin{tabularx}{140mm}{l}
 ++++++ Stop MPI\\
 *** Broadcast STOP signal\\
 *** MPI is peacefully finalized\\
\end{tabularx}
}}}\\

\noindent と記述される。
``history.pe000000.nc''と``history.pe000001.nc''
の2つのファイルが計算結果が記録されたhistoryファイルである。
2-MPI並列で実行したため、2つのファイルが生成されており、
ファイル形式はNetCDFである。
``monitor.pe000000''は、計算中にモニタリングしている
物理変数の時間変化を記録したテキストファイルである。



\subsection{後処理と描画}
%------------------------------------------------------
ここでは、計算結果を描画するための後処理について説明する。本書のチュートリアルでは、
NetCDF形式の分散ファイルを1つのファイルにまとめ、ユーザーが解析しやすいDirect-Accessの
単純バイナリ形式（GrADS形式）に変換する方法を説明する。
%Gphys/Ruby-DCLを使うと
%分割ファイルのまま直接描画することができるが、この方法については\ref{sec:quicklook}節を
%参照してもらいたい。

まず、\ref{sec:source_net2g}節でコンパイルした後処理ツール``net2g''を、
現在のディレクトリへリンクを張る。
\begin{verbatim}
  $ ln -s ../../../util/netcdf2grads_h/net2g  ./
\end{verbatim}
もし、ここで説明するディレクトリとは異なる場所で実行している場合は、
リンクを張る時のディレクトリ指定に注意すること。

net2gも実行方法は基本的にSCALE本体と同じである。
\begin{verbatim}
  $ mpirun  -n  [プロセス数]  ./net2g  [configファイル]
\end{verbatim}
net2g専用の``\verb|net2g.conf|''をconfigファイルとして与えて、
つぎのように実行する。
\begin{verbatim}
  $ mpirun  -n  2  ./net2g  net2g.conf
\end{verbatim}

\noindent net2gの実行にあたっては、SCALE本体の実行時に使用したMPIプロセス数と同じか、
その約数のプロセス数を用いて実行しなければならない。
%HDDの読み書き速度に依存するが、本書の必要要件にあった計算機であれば2分程度で計算が終わる。
この実行によって、書き6つのファイルが、実行ディレクトリ下に作成される。
\begin{verbatim}
  QHYD_d01z-3d.ctl
  QHYD_d01z-3d.grd
  U_d01z-3d.ctl
  U_d01z-3d.grd
  W_d01z-3d.ctl
  W_d01z-3d.grd
\end{verbatim}
これらのファイルはぞれぞれ、
U（水平風東西成分）、W（鉛直風）、QHYD（全凝結物混合比）について、
分割ファイルを1つにまとめ、Direct-Accessの単純バイナリ形式（GrADS形式）に
変換したgrdファイルとGrADSに読み込ませるためのctlファイルである。
従って、このctlファイルをGrADSに読み込ませれば
直ちに計算結果の描画が可能である。
図\ref{fig_ideal}は、積分開始1200秒後における、
U-WとQHYDについての鉛直断面図である。


``\verb|net2g.conf|''の下記の行を編集することによって、
他の変数についても変換が可能である。\\

\noindent {\small {\gt
\ovalbox{
\begin{tabularx}{140mm}{l}
\verb|&VARI|\\
\verb| VNAME       = "U","W","QHYD"|\\
\verb|/|\\
\end{tabularx}
}}}\\

\noindent この``VNAME''の項目を例えば、
\verb|"PT","RH"|と変更して実行すれば温位と相対湿度の変数に
ついて変換する。どの変数が出力されているのかを調べるには、NetCDFのncdumpツールなどを
使えば簡単に調べられる。net2gの詳しい使用方法は、\ref{sec:net2g}を参照してほしい。


\begin{figure}[t]
\begin{center}
  \includegraphics[width=1.0\hsize]{./figure/grads_hist_ideal.eps}\\
  \caption{積分開始後 1200 sec のY=1 kmにおける東西-鉛直断面図；
           (a)のカラーシェードは全凝結物の混合比、
           (b)は鉛直速度をそれぞれ示す。ベクトルは東西-鉛直断面内の風の流れを表す。}
  \label{fig_ideal}
\end{center}
\end{figure}




\subsubsection{この章の最後に}

本章では、スコールラインの理想実験を例に、SCALEの実行方法について説明した。
次ステップとして、
解像度や計算領域、MPIプロセス数の変更
放射過程や乱流過程、雲微物理スキームといった物理過程の変更を
試すことをお勧めする。
これらの変更方法は、第\ref{sec:basic}章に記載されている。

このスコールラインの理想実験については、
同じディレクトリ下の``sample''ディレクトリ内に、
解像度設定、領域設定、使用する物理スキームについて変更を加えたconfigファイルのサンプルが用意されているので、
これらも参考となる。
また、SCALEには各種理想実験セットが``\verb|scale-rm/test/case|''以下に複数用意されている。
ディレクトリ構造がチュートリアルとは
異なる部分もあるが、実行手順は基本的に本章のチュートリアルと同じである。


